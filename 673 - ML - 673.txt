Several learning algorithms aim at discovering better representations of the inputs provided during training.[25] 
Classic examples include principal components analysis and cluster analysis. Feature learning algorithms, also called 
representation learning algorithms, often attempt to preserve the information in their input but also transform it in a way 
that makes it useful, often as a pre-processing step before performing classification or predictions. This technique allows 
reconstruction of the inputs coming from the unknown data-generating distribution, while not being necessarily faithful to 
configurations that are implausible under that distribution.